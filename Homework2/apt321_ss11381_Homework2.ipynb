{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Homework 2\n",
    "\n",
    "### Submission By:  \n",
    "<ul>\n",
    "    <li>Akshay Prakash Tambe (apt321@nyu.edu)</li>\n",
    "    <li>Snahil Singh (ss11381@nyu.edu)</li>\n",
    "</ul>\n",
    "\n",
    "Please run below command if you need any packages to be installed while running this notebook:\n",
    "```\n",
    "import sys\n",
    "!{sys.executable} -m pip install <package-name>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Programming Exercise\n",
    "\n",
    "### Question 1 (a):   \n",
    "##### Implement a version of k-Nearest Neighbor to classify the test examples, using the training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data():\n",
    "    # Loading Comma Seperated Data using read_table pandas function in 'reviews_train_data' dataframe\n",
    "    reviews_train_data = pd.read_csv(\"reviewstrain.txt\", delimiter=\"\\t\", header=None)\n",
    "    reviews_train_data = pd.DataFrame(reviews_train_data)\n",
    "\n",
    "    # Splitting Dataset into \"labels\" and \"reviews_text\"\n",
    "    reviews_train_data = pd.DataFrame(reviews_train_data[0].str.split(' ',1).tolist(), columns = ['label','reviews_text'])\n",
    "\n",
    "    # Loading Comma Seperated Data using read_table pandas function in 'reviews_test_data' dataframe\n",
    "    reviews_test_data = pd.read_csv(\"reviewstest.txt\", delimiter=\"\\t\", header=None)\n",
    "    reviews_test_data = pd.DataFrame(reviews_test_data)\n",
    "\n",
    "    # Splitting Dataset into \"labels\" and \"reviews_text\"\n",
    "    reviews_test_data = pd.DataFrame(reviews_test_data[0].str.split(' ',1).tolist(), columns = ['label','reviews_text'])\n",
    "    return reviews_train_data, reviews_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                       reviews_text\n",
      "0        1  a stirring , funny and finally transporting re...\n",
      "1        1  a real winner -- smart , funny , subtle , and ...\n",
      "2        0  a dim-witted and lazy spin-off of the animal p...\n",
      "3        1  ` anyone with a passion for cinema , and indee...\n",
      "4        0  a crass and insulting homage to great films li...\n",
      "5        0                              an infuriating film .\n",
      "6        0  stealing harvard will dip into your wallet , s...\n",
      "7        1  a poignant lyricism runs through balzac and th...\n",
      "8        0  it 's always disappointing when a documentary ...\n",
      "9        1  there are scenes of cinematic perfection that ...\n",
      "10       0  what ensues are much blood-splattering , mass ...\n",
      "11       1                             an impressive hybrid .\n",
      "12       0  the script 's judgment and sense of weight is ...\n",
      "13       0  it ends up being neither , and fails at both e...\n",
      "14       1                    it is definitely worth seeing .\n",
      "15       0  it does n't take a rocket scientist to figure ...\n",
      "16       0     constantly slips from the grasp of its maker .\n",
      "17       0  quite frankly , i ca n't see why any actor of ...\n",
      "18       0  feels at times like a giant commercial for uni...\n",
      "19       1  i 'd watch these two together again in a new y...\n",
      "20       0  tartakovsky 's team has some freakish powers o...\n",
      "21       0                                        bad movie .\n",
      "22       1  and your reward will be a thoughtful , emotion...\n",
      "23       1  everyone 's insecure in lovely and amazing , a...\n",
      "24       1                  the movie is brilliant , really .\n",
      "25       1  what could have easily become a cold , calcula...\n",
      "26       1  solaris is rigid and evasive in ways that sode...\n",
      "27       1  captivates and shows how a skillful filmmaker ...\n",
      "28       0                       as pedestrian as they come .\n",
      "29       0  the issues are presented in such a lousy way ,...\n",
      "...    ...                                                ...\n",
      "1470     0        i have to admit i walked out of runteldat .\n",
      "1471     1                   adaptation is simply brilliant .\n",
      "1472     1  fifty years after the fact , the world 's poli...\n",
      "1473     0  but the movie that does n't really deliver for...\n",
      "1474     1  despite its floating narrative , this is a rem...\n",
      "1475     0  if ever such a dependable concept was botched ...\n",
      "1476     0  the french director has turned out nearly 21\\/...\n",
      "1477     0  it desperately wants to be a wacky , screwball...\n",
      "1478     0  it 's difficult to conceive of anyone who has ...\n",
      "1479     1             a conventional but heartwarming tale .\n",
      "1480     1  you feel good , you feel sad , you feel pissed...\n",
      "1481     0  a particularly joyless , and exceedingly dull ...\n",
      "1482     0  how about surprising us by trying something new ?\n",
      "1483     1  secretary manages a neat trick , bundling the ...\n",
      "1484     1  a smart , sassy and exceptionally charming rom...\n",
      "1485     1  a distinguished and thoughtful film , marked b...\n",
      "1486     1  wo n't be placed in the pantheon of the best o...\n",
      "1487     0                by that measure , it is a failure .\n",
      "1488     0  but it 's hard to imagine a more generic effor...\n",
      "1489     1  a minor film with major pleasures from portugu...\n",
      "1490     1  it 's refreshing to see a movie that embraces ...\n",
      "1491     1  it tends to remind one of a really solid woody...\n",
      "1492     1  a brisk , reverent , and subtly different sequ...\n",
      "1493     1                          exciting and well-paced .\n",
      "1494     1  the history is fascinating ; the action is daz...\n",
      "1495     1                      great character interaction .\n",
      "1496     0  if there was any doubt that peter o'fallon did...\n",
      "1497     1  a pretty funny movie , with most of the humor ...\n",
      "1498     1  an enthralling aesthetic experience , one that...\n",
      "1499     0  due to stodgy , soap opera-ish dialogue , the ...\n",
      "\n",
      "[1500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "reviews_train_data, reviews_test_data = load_data()\n",
    "print(reviews_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    811\n",
      "0    689\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking if dataset is balanced for training --> Balanced Dataset\n",
    "print(reviews_train_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label                                       reviews_text\n",
      "0       1  funny , sexy , devastating and incurably roman...\n",
      "1       1       cool gadgets and creatures keep this fresh .\n",
      "2       1  fathers and sons , and the uneasy bonds betwee...\n",
      "3       0  after that it becomes long and tedious like a ...\n",
      "4       0  what should have been a cutting hollywood sati...\n",
      "5       0  nothing about the film -- with the possible ex...\n",
      "6       1  the overall result is an intelligent , realist...\n",
      "7       1                 `` red dragon '' is entertaining .\n",
      "8       0  despite all the closed-door hanky-panky , the ...\n",
      "9       1  a genuinely funny ensemble comedy that also as...\n",
      "10      1  the film is moody , oozing , chilling and hear...\n",
      "11      0  it appears to have been made by people to whom...\n",
      "12      1  as the movie traces mr. brown 's athletic expl...\n",
      "13      1  the art direction is often exquisite , and the...\n",
      "14      1  by turns touching , raucously amusing , uncomf...\n",
      "15      1  this chicago has hugely imaginative and succes...\n",
      "16      1                       cho 's timing is priceless .\n",
      "17      1  it leaves little doubt that kidman has become ...\n",
      "18      0  much like its easily dismissive take on the up...\n",
      "19      1             the performances are an absolute joy .\n",
      "20      1  sensitive ensemble performances and good perio...\n",
      "21      1  the film sparkles with the the wisdom and humo...\n",
      "22      0  swims in mediocrity , sticking its head up for...\n",
      "23      1  spectacularly beautiful , not to mention myste...\n",
      "24      0  a loud , low-budget and tired formula film tha...\n",
      "25      1  such master screenwriting comes courtesy of jo...\n",
      "26      0                  an empty , purposeless exercise .\n",
      "27      1  if you like quirky , odd movies and\\/or the ir...\n",
      "28      0  it 's too interested in jerking off in all its...\n",
      "29      0  devoid of any of the qualities that made the f...\n",
      "..    ...                                                ...\n",
      "470     0  a banal , virulently unpleasant excuse for a r...\n",
      "471     0  it 's crap on a leash -- far too polite to sca...\n",
      "472     1                                    spiderman rocks\n",
      "473     1  these people are really going to love the pian...\n",
      "474     0        stiff and schmaltzy and clumsily directed .\n",
      "475     1  a well paced and satisfying little drama that ...\n",
      "476     1                 hard , endearing , caring , warm .\n",
      "477     1  nicholson 's understated performance is wonder...\n",
      "478     1  it 's a fairy tale that comes from a renowned ...\n",
      "479     0  a work that lacks both a purpose and a strong ...\n",
      "480     0  every conceivable mistake a director could mak...\n",
      "481     0  lacks the inspiration of the original and has ...\n",
      "482     0  instead of making his own style , director mar...\n",
      "483     1                               a stylish thriller .\n",
      "484     0                      the most repugnant adaptation\n",
      "485     0  equilibrium the movie , as opposed to the mani...\n",
      "486     1  a breathtaking adventure for all ages , spirit...\n",
      "487     0  it 's just too bad the screenwriters eventuall...\n",
      "488     0  the exclamation point seems to be the only bit...\n",
      "489     1          the entire cast is extraordinarily good .\n",
      "490     0  `` interview '' loses its overall sense of mys...\n",
      "491     0                     an extremely unpleasant film .\n",
      "492     1  speaks eloquently about the symbiotic relation...\n",
      "493     1  it 's funny , touching , dramatically forceful...\n",
      "494     0  one of those films that started with a great p...\n",
      "495     1  give credit to everyone from robinson down to ...\n",
      "496     1  while it 's nothing we have n't seen before fr...\n",
      "497     0  some of the characters die and others do n't ,...\n",
      "498     0  it 's horribly depressing and not very well do...\n",
      "499     1  texan director george ratliff had unlimited ac...\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(reviews_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Distance Function --> inter(c1, c2) is the set of distinct tokens appearing in both x and y.\n",
    "import numpy as np\n",
    "def inter(x, y):\n",
    "    common_tokens = set(y).intersection(x)\n",
    "    if len(common_tokens) == 0:\n",
    "        distance = np.nan\n",
    "    else:\n",
    "        distance = 1/len(common_tokens)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get K Nearest Neighbours Function\n",
    "def get_k_neighbours(k, dataframe):\n",
    "    # Sort the training examples by distance from the test example, smallest to largest\n",
    "    dataframe = dataframe.sort_values(by=['distance'])\n",
    "    \n",
    "    # If there are other neighbors at the same distance as the 5th one on this list, include them also\n",
    "    top_k = dataframe.head(k)\n",
    "    top_kth_distance = dataframe[(k-1):].distance.values[0]\n",
    "    dataframe = dataframe.drop(dataframe.index[0:k])\n",
    "    dataframe = dataframe[dataframe['distance']==top_kth_distance]\n",
    "    top_k = top_k.append(dataframe)\n",
    "    \n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Prediction Labels for given test dataset\n",
    "def get_predictions(k,reviews_test_data, reviews_train_data):\n",
    "    #i = 0 #Counter for debugging\n",
    "    predictions = []\n",
    "    # Reading each test row\n",
    "    for test_row in reviews_test_data.itertuples():\n",
    "        test_row_tokens = test_row.reviews_text.split()\n",
    "        distance = []\n",
    "        # Comparing each test row with each training row\n",
    "        for train_row in reviews_train_data.itertuples():\n",
    "            train_text = train_row.reviews_text\n",
    "            train_row_tokens = train_row.reviews_text.split()\n",
    "            # Calculating distance of test row from each training row\n",
    "            distance.append(inter(train_row_tokens, test_row_tokens))\n",
    "        # Dataframe with distances stored for each test row\n",
    "        string_match={\n",
    "            'k_nearest_train_text': reviews_train_data.reviews_text,\n",
    "            'distance': distance,\n",
    "            'label': reviews_train_data.label\n",
    "        }\n",
    "        string_match = pd.DataFrame(string_match)\n",
    "        # Get K Nearest Neighbours for each test row\n",
    "        string_match = get_k_neighbours(k,string_match)\n",
    "        # Prediction Label for each test row\n",
    "        try:\n",
    "            predicted_num0 = string_match['label'].value_counts()['0']\n",
    "        except KeyError:\n",
    "            predicted_num0 = 0\n",
    "        try:\n",
    "            predicted_num1 = string_match['label'].value_counts()['1']\n",
    "        except KeyError:\n",
    "            predicted_num1 = 0\n",
    "        if predicted_num0 > predicted_num1:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(1)\n",
    "        # Deleting Dataframe to optimize memory\n",
    "        del string_match\n",
    "        #i = i + 1 #Counter for debugging\n",
    "    \n",
    "    # Final Prediction Dataframe\n",
    "    predicted_test_data = {\n",
    "        'testdata_reviews_text': reviews_test_data.reviews_text,\n",
    "        'actual_label': reviews_test_data.label,\n",
    "        'predicted_label': predictions\n",
    "    }\n",
    "    predicted_test_data = pd.DataFrame(predicted_test_data)\n",
    "\n",
    "    return predicted_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Accuracy, TP/TN/FP/FN of the Model\n",
    "def get_model_metrics(predicted_test_data):\n",
    "    # Initializing variables\n",
    "    correct_pred = 0\n",
    "    total_pred = 0\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for row in predicted_test_data.itertuples():\n",
    "        total_pred = total_pred + 1\n",
    "        # Correct Predictions\n",
    "        if int(row.actual_label) == int(row.predicted_label):\n",
    "            correct_pred = correct_pred + 1\n",
    "            # True Positive\n",
    "            if (int(row.actual_label) == 1 and int(row.predicted_label) == 1):\n",
    "                true_positive = true_positive + 1\n",
    "            # True Negative\n",
    "            elif  (int(row.actual_label) == 0 and int(row.predicted_label) == 0):   \n",
    "                    true_negative = true_negative + 1\n",
    "        # False Positive\n",
    "        elif  (int(row.actual_label) == 0 and int(row.predicted_label) == 1):   \n",
    "                false_positive = false_positive + 1\n",
    "        # False Negative\n",
    "        elif  (int(row.actual_label) == 1 and int(row.predicted_label) == 0):   \n",
    "                false_negative = false_negative + 1\n",
    "    # Accuracy\n",
    "    accuracy = (correct_pred/total_pred)*100\n",
    "    tpr = true_positive/(true_positive + false_negative)\n",
    "    fpr = false_positive/(false_positive + true_negative)\n",
    "    \n",
    "    # Model Metrics Dataframe\n",
    "    model_metrics = {\n",
    "        'total_predictions': total_pred, \n",
    "        'correct_predictions': correct_pred, \n",
    "        'accuracy': accuracy, \n",
    "        'true_positive': true_positive, \n",
    "        'false_positive': false_positive, \n",
    "        'true_negative': true_negative, \n",
    "        'false_negative': false_negative,\n",
    "        'tpr': tpr,\n",
    "        'fpr': fpr\n",
    "    }\n",
    "    \n",
    "    return model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running KNN Classifier for K=1 for given training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "predicted_test_data = get_predictions(k, reviews_test_data, reviews_train_data)\n",
    "model_metrics = get_model_metrics(predicted_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question i) : \n",
    "For k = 1, what is the predicted label for the following example in the test set: \"It leaves little doubt that Kidman has become one of our best actors .\" (This is line 18 of the test file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.a.i) Predicted label for the following example in the test set is:  1\n"
     ]
    }
   ],
   "source": [
    "predicted_label = predicted_test_data['predicted_label'][predicted_test_data['testdata_reviews_text'] == \\\n",
    "        \"it leaves little doubt that kidman has become one of our best actors .\"].values[0]\n",
    "print(\"Answer 1.a.i) Predicted label for the following example in the test set is: \", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question ii)\n",
    "What is the confusion matrix (on the test set) for k = 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.a.ii)\n",
      "True Positive = 209\tFalse Negative = 64\n",
      "False Positive = 134\tTrue Negative = 93\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer 1.a.ii)\")\n",
    "print(\"True Positive = \" + str(model_metrics['true_positive']) \\\n",
    "      + \"\\tFalse Negative = \" + str(model_metrics['false_negative']))\n",
    "print(\"False Positive = \" + str(model_metrics['false_positive']) \\\n",
    "      + \"\\tTrue Negative = \" + str(model_metrics['true_negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question iii)\n",
    "Report the accuracy, the true positive rate, and the false positive rate, on the test set for k = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.a.iii)\n",
      "Accuracy =  60.4\n",
      "True Positive Rate =  0.7655677655677655\n",
      "False Positive Rate =  0.5903083700440529\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer 1.a.iii)\")\n",
    "accuracy = model_metrics['accuracy']\n",
    "tpr = model_metrics['tpr']\n",
    "fpr = model_metrics['fpr']\n",
    "print(\"Accuracy = \", accuracy)\n",
    "print(\"True Positive Rate = \", tpr)\n",
    "print(\"False Positive Rate = \", fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running KNN Classifier for K=5 for given training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "predicted_test_data = get_predictions(k, reviews_test_data, reviews_train_data)\n",
    "model_metrics = get_model_metrics(predicted_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question iv)\n",
    "For k = 5, what is the predicted label for the following example in the test set: \"It leaves little doubt that Kidman has become one of our best actors .\"(This is line 18 of the test file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.a.iv) Predicted label for the following example in the test set is:  1\n"
     ]
    }
   ],
   "source": [
    "predicted_label = predicted_test_data['predicted_label'][predicted_test_data['testdata_reviews_text'] == \\\n",
    "        \"it leaves little doubt that kidman has become one of our best actors .\"].values[0]\n",
    "print(\"Answer 1.a.iv) Predicted label for the following example in the test set is: \", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question v)\n",
    "What is the confusion matrix (on the test set) for k = 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.a.v)\n",
      "True Positive = 212\tFalse Negative = 61\n",
      "False Positive = 136\tTrue Negative = 91\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer 1.a.v)\")\n",
    "print(\"True Positive = \" + str(model_metrics['true_positive']) \\\n",
    "      + \"\\tFalse Negative = \" + str(model_metrics['false_negative']))\n",
    "print(\"False Positive = \" + str(model_metrics['false_positive']) \\\n",
    "      + \"\\tTrue Negative = \" + str(model_metrics['true_negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question vi)\n",
    "Report the accuracy, the true positive rate, and the false positive rate, on the test set for k = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.a.vi)\n",
      "Accuracy =  60.6\n",
      "True Positive Rate =  0.7765567765567766\n",
      "False Positive Rate =  0.5991189427312775\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer 1.a.vi)\")\n",
    "accuracy = model_metrics['accuracy']\n",
    "tpr = model_metrics['true_positive']/(model_metrics['true_positive'] + model_metrics['false_negative'])\n",
    "fpr = model_metrics['false_positive']/(model_metrics['false_positive'] + model_metrics['true_negative'])\n",
    "print(\"Accuracy = \", accuracy)\n",
    "print(\"True Positive Rate = \", tpr)\n",
    "print(\"False Positive Rate = \", fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question vii)\n",
    "What is the accuracy on the test set for k = 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  60.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question viii)\n",
    "Suppose we used the very simple Zero-R classifier on this dataset, rather than k-NN. That is, we classify all examples in the test set as belonging to the class that is more common in the training set. What is the resulting confusion matrix (on the test set)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-R Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero-R Classifier\n",
    "def zero_r_classifier(reviews_test_data, reviews_train_data):\n",
    "    label_1 = reviews_train_data['label'].value_counts()[0]\n",
    "    label_0 = reviews_train_data['label'].value_counts()[1]\n",
    "    \n",
    "    # Majority in training set is Zero-R Label\n",
    "    if label_1 > label_0:\n",
    "        zero_r_label = 1\n",
    "    else: \n",
    "        zero_r_label = 0\n",
    "    \n",
    "    # Adding Zero-R Predicted Label in Test Dataset\n",
    "    predicted_test_data = {\n",
    "        'testdata_reviews_text': reviews_test_data.reviews_text,\n",
    "        'actual_label': reviews_test_data.label,\n",
    "        'predicted_label': zero_r_label\n",
    "    }\n",
    "    predicted_test_data = pd.DataFrame(predicted_test_data)\n",
    "    return predicted_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.a.viii)\n",
      "True Positive = 273\tFalse Negative = 0\n",
      "False Positive = 227\tTrue Negative = 0\n"
     ]
    }
   ],
   "source": [
    "# Running Zero R Classifier on given datasets\n",
    "predicted_test_data = zero_r_classifier(reviews_test_data, reviews_train_data)\n",
    "model_metrics = get_model_metrics(predicted_test_data)\n",
    "print(\"Answer 1.a.viii)\")\n",
    "print(\"True Positive = \" + str(model_metrics['true_positive']) \\\n",
    "      + \"\\tFalse Negative = \" + str(model_metrics['false_negative']))\n",
    "print(\"False Positive = \" + str(model_metrics['false_positive']) \\\n",
    "      + \"\\tTrue Negative = \" + str(model_metrics['true_negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (c):\n",
    "Implement 5-fold cross-validation on the training set to determine which of the following values of k works better in k-NN: 3, 7, 99. (When there are more than k possible nearest 7 neighbors, because of multiple points at the same distance from the test set, handle this analogously to how you handled it in part 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  3\n",
      "Accuracy =  66.06666666666666\n",
      "----------------------------------------------------------------------\n",
      "For K =  7\n",
      "Accuracy =  65.86666666666666\n",
      "----------------------------------------------------------------------\n",
      "For K =  99\n",
      "Accuracy =  61.199999999999996\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "k_list = [3, 7, 99]\n",
    "k_df = {}\n",
    "for k in k_list:\n",
    "    prediction = pd.DataFrame(columns=['testdata_reviews_text','actual_label','predicted_label'])\n",
    "    for i in range(5):\n",
    "        #print('Cross Validation Fold Spilt: ', i)\n",
    "        reviews_test_data1 = reviews_train_data[(i*300):(i*300)+300]\n",
    "        reviews_train_data1 = reviews_train_data.drop(reviews_train_data.index[(i*300):(i*300)+300])\n",
    "        predicted_test_data = get_predictions(k,reviews_test_data1,reviews_train_data1)\n",
    "        prediction = prediction.append(predicted_test_data)\n",
    "    correct_pred = 0\n",
    "    total_pred = 0\n",
    "    for row in prediction.itertuples():\n",
    "        total_pred = total_pred + 1\n",
    "        if int(row.actual_label) == int(row.predicted_label):\n",
    "            correct_pred =correct_pred + 1\n",
    "    print(\"For K = \", k)\n",
    "    #print('Correction Predictions = ', correct_pred)\n",
    "    #print('Total Predictions = ', total_pred)\n",
    "    accuracy = (correct_pred/total_pred)*100\n",
    "    print('Accuracy = ', accuracy)\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    k_df.update({k : accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question i)\n",
    "For each of the 3 values of k, what is the cross-validation accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.b.i)\n",
      "Cross Validation Accuracies\n",
      "{3: 66.06666666666666, 7: 65.86666666666666, 99: 61.199999999999996}\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer 1.b.i)\")\n",
    "print(\"Cross Validation Accuracies\")\n",
    "print(k_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question ii)\n",
    "Take the k that had the highest cross-validation accuracy. Run k-NN on the entire training set for this value of k, and then test on the test set. Give the confusion matrix and the accuracy (for the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest K =  3\n"
     ]
    }
   ],
   "source": [
    "# Taking Highest K\n",
    "max_key = max(k_df, key=lambda k: k_df[k])\n",
    "print(\"Highest K = \", max_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run k-NN on the entire training set for this value of highest k, and then test on the test set\n",
    "k = max_key\n",
    "predicted_test_data = get_predictions(k, reviews_test_data, reviews_train_data)\n",
    "model_metrics = get_model_metrics(predicted_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.b.ii)\n",
      "True Positive = 212\tFalse Negative = 61\n",
      "False Positive = 144\tTrue Negative = 83\n",
      "Accuracy =  59.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer 1.b.ii)\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"True Positive = \" + str(model_metrics['true_positive']) \\\n",
    "      + \"\\tFalse Negative = \" + str(model_metrics['false_negative']))\n",
    "print(\"False Positive = \" + str(model_metrics['false_positive']) \\\n",
    "      + \"\\tTrue Negative = \" + str(model_metrics['true_negative']))\n",
    "\n",
    "# Accuracy\n",
    "accuracy = model_metrics['accuracy']\n",
    "print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (d):\n",
    "Experiment with using a different distance function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Refined Intersection Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "def refine_tokens_inter_distance(dataframe):\n",
    "    # Remove special characters, numbers, punctuations\n",
    "    dataframe['reviews_text'] = dataframe['reviews_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    \n",
    "    # Removing Short Words\n",
    "    dataframe['reviews_text'] = dataframe['reviews_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    dataframe = dataframe.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
    "    \n",
    "    # Removing of Stop Words\n",
    "    stop = stopwords.words('english')\n",
    "    dataframe['reviews_text'] = dataframe['reviews_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jaccard Similarity Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity_distance(x, y):\n",
    "    z = x.intersection(y)\n",
    "    return 1 - float(len(z)) / (len(x) + len(y) - len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Prediction Labels for given test dataset using Jaccard Similarity Distance\n",
    "def get_predictions_jaccard(k,reviews_test_data, reviews_train_data):\n",
    "    #i = 0 #Counter for debugging\n",
    "    predictions = []\n",
    "    # Reading each test row\n",
    "    for test_row in reviews_test_data.itertuples():\n",
    "        test_row_tokens = test_row.reviews_text.split()\n",
    "        distance = []\n",
    "        # Comparing each test row with each training row\n",
    "        for train_row in reviews_train_data.itertuples():\n",
    "            train_text = train_row.reviews_text\n",
    "            train_row_tokens = train_row.reviews_text.split()\n",
    "            # Calculating distance of test row from each training row using jaccard\n",
    "            distance.append(jaccard_similarity_distance(set(train_row_tokens), set(test_row_tokens)))\n",
    "        # Dataframe with distances stored for each test row\n",
    "        string_match={\n",
    "            'k_nearest_train_text': reviews_train_data.reviews_text,\n",
    "            'distance': distance,\n",
    "            'label': reviews_train_data.label\n",
    "        }\n",
    "        string_match = pd.DataFrame(string_match)\n",
    "        # Get K Nearest Neighbours for each test row\n",
    "        string_match = get_k_neighbours(k,string_match)\n",
    "        # Prediction Label for each test row\n",
    "        try:\n",
    "            predicted_num0 = string_match['label'].value_counts()['0']\n",
    "        except KeyError:\n",
    "            predicted_num0 = 0\n",
    "        try:\n",
    "            predicted_num1 = string_match['label'].value_counts()['1']\n",
    "        except KeyError:\n",
    "            predicted_num1 = 0\n",
    "        if predicted_num0 > predicted_num1:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(1)\n",
    "        # Deleting Dataframe to optimize memory\n",
    "        del string_match\n",
    "        #i = i + 1 #Counter for debugging\n",
    "    \n",
    "    # Final Prediction Dataframe\n",
    "    predicted_test_data = {\n",
    "        'testdata_reviews_text': reviews_test_data.reviews_text,\n",
    "        'actual_label': reviews_test_data.label,\n",
    "        'predicted_label': predictions\n",
    "    }\n",
    "    predicted_test_data = pd.DataFrame(predicted_test_data)\n",
    "\n",
    "    return predicted_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_choice(function, k, reviews_test_data, reviews_train_data):\n",
    "    if function == '2':\n",
    "        print(\"Using Refined Intersection Distance...\")\n",
    "        refined_reviews_test_data = refine_tokens_inter_distance(reviews_test_data)\n",
    "        refined_reviews_train_data = refine_tokens_inter_distance(reviews_train_data)\n",
    "        predicted_test_data = get_predictions(k, refined_reviews_test_data, refined_reviews_train_data)\n",
    "    elif function == '3':\n",
    "        print(\"Using Jaccard Distance...\")\n",
    "        predicted_test_data = get_predictions_jaccard(k, reviews_test_data, reviews_train_data)\n",
    "    else:\n",
    "        print(\"Using Default Distance...\")\n",
    "        predicted_test_data = get_predictions(k, reviews_test_data, reviews_train_data)\n",
    "    return predicted_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Default Distance\n",
      "2: Refined Intersection Distance\n",
      "3: Jaccard Distance\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take User Input\n",
    "import sys\n",
    "if sys.version_info[0] >= 3:\n",
    "    raw_input = input\n",
    "user_input = raw_input(\"1: Default Distance\\n2: Refined Intersection Distance\\n3: Jaccard Distance\\n\")\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Refined Intersection Distance...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.8,\n",
       " 'correct_predictions': 364,\n",
       " 'false_negative': 44,\n",
       " 'false_positive': 92,\n",
       " 'fpr': 0.4052863436123348,\n",
       " 'total_predictions': 500,\n",
       " 'tpr': 0.8388278388278388,\n",
       " 'true_negative': 135,\n",
       " 'true_positive': 229}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "reviews_train_data, reviews_test_data = load_data()\n",
    "\n",
    "k = 1\n",
    "predicted_test_data = get_predictions_choice(user_input, k, reviews_test_data, reviews_train_data)\n",
    "model_metrics = get_model_metrics(predicted_test_data)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running for all Distances for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For User Input = 1\n",
      "For K = 1\n",
      "Using Default Distance...\n",
      "{'total_predictions': 500, 'correct_predictions': 302, 'accuracy': 60.4, 'true_positive': 209, 'false_positive': 134, 'true_negative': 93, 'false_negative': 64, 'tpr': 0.7655677655677655, 'fpr': 0.5903083700440529}\n",
      "------------------------------------------------------------------------------------------------------\n",
      "For User Input = 1\n",
      "For K = 5\n",
      "Using Default Distance...\n",
      "{'total_predictions': 500, 'correct_predictions': 303, 'accuracy': 60.6, 'true_positive': 212, 'false_positive': 136, 'true_negative': 91, 'false_negative': 61, 'tpr': 0.7765567765567766, 'fpr': 0.5991189427312775}\n",
      "------------------------------------------------------------------------------------------------------\n",
      "For User Input = 2\n",
      "For K = 1\n",
      "Using Refined Intersection Distance...\n",
      "{'total_predictions': 500, 'correct_predictions': 364, 'accuracy': 72.8, 'true_positive': 229, 'false_positive': 92, 'true_negative': 135, 'false_negative': 44, 'tpr': 0.8388278388278388, 'fpr': 0.4052863436123348}\n",
      "------------------------------------------------------------------------------------------------------\n",
      "For User Input = 2\n",
      "For K = 5\n",
      "Using Refined Intersection Distance...\n",
      "{'total_predictions': 500, 'correct_predictions': 370, 'accuracy': 74.0, 'true_positive': 236, 'false_positive': 93, 'true_negative': 134, 'false_negative': 37, 'tpr': 0.8644688644688645, 'fpr': 0.40969162995594716}\n",
      "------------------------------------------------------------------------------------------------------\n",
      "For User Input = 3\n",
      "For K = 1\n",
      "Using Jaccard Distance...\n",
      "{'total_predictions': 500, 'correct_predictions': 321, 'accuracy': 64.2, 'true_positive': 206, 'false_positive': 112, 'true_negative': 115, 'false_negative': 67, 'tpr': 0.7545787545787546, 'fpr': 0.4933920704845815}\n",
      "------------------------------------------------------------------------------------------------------\n",
      "For User Input = 3\n",
      "For K = 5\n",
      "Using Jaccard Distance...\n",
      "{'total_predictions': 500, 'correct_predictions': 334, 'accuracy': 66.8, 'true_positive': 220, 'false_positive': 113, 'true_negative': 114, 'false_negative': 53, 'tpr': 0.8058608058608059, 'fpr': 0.4977973568281938}\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_list = ['1', '2', '3']\n",
    "k_list = [1, 5]\n",
    "for distance_function in input_list:\n",
    "    for k in k_list:\n",
    "        print(\"For User Input = \"+str(distance_function))\n",
    "        print(\"For K = \"+str(k))\n",
    "        reviews_train_data, reviews_test_data = load_data()\n",
    "        predicted_test_data = get_predictions_choice(distance_function, k, reviews_test_data, reviews_train_data)\n",
    "        model_metrics = get_model_metrics(predicted_test_data)\n",
    "        print(model_metrics)\n",
    "        print(\"------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question i):\n",
    "Describe your distance function. How is the distance between two comments computed? Include an example in your explanation.  \n",
    "\n",
    "We have used two distance functions where I have achieved higher accuracy in the model than our default distance function.  \n",
    "### 1. Refined Intersection Distance  \n",
    "This distance function manipulates the string text by removing redundantant texts whuch can be considered for comparison and then calculates the distance using our same formula. For this method, we will get different distance scores for some of the text which refines our accuracy.\n",
    "The following function performs below manipulation before taking distance:\n",
    "<ul>\n",
    "    <li>**Remove special characters, numbers, punctuations:** We can also think of getting rid of the punctuations, numbers and even special characters since they wouldn’t help in differentiating different kinds of reviews. Hence, it is better to remove them from the text.</li>\n",
    "    <li>**Remove Short Words:** Most of the smaller words do not add much value. For example, 'pdx', 'his', 'all', 'the', 'her'. So, we will try to remove them as well from our data. We were little careful here in selecting the length of the words which we want to remove. So, we decided to remove all the words having length 3 or less. For example, terms like “hmm”, “oh” are of very little use. It is better to get rid of them.</li>\n",
    "    <li>**Stemming:**: Stemming is a rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word. For example, For example – “play”, “player”, “played”, “plays” and “playing” are the different variations of the word – “play”.</li>\n",
    "    <li>**Removing of Stop Words:** Removing stop words like 'a', 'the' will help to calculate similarity distances more effectively.</li>   \n",
    "</ul>\n",
    "\n",
    "### 2. Jaccard Similarity Distance\n",
    "The Jaccard similarity index (sometimes called the Jaccard similarity coefficient) compares members for two sets to see which members are shared and which are distinct. It’s a measure of similarity for the two sets of data, with a range from 0% to 100%. The higher the percentage, the more similar the two populations.\n",
    "\n",
    "The formula to find the Index is:\n",
    "\n",
    "```\n",
    "Jaccard Index = (the number in both sets) / (the number in either set) * 100\n",
    "```\n",
    "\n",
    "A simple example using set notation: How similar are these two sets?\n",
    "```\n",
    "A = {0,1,2,5,6}\n",
    "B = {0,2,3,4,5,7,9}\n",
    "J(A,B) = |A∩B| / |A∪B| = |{0,2,5}| / |{0,1,2,3,4,5,6,7,9}| = 3/9 = 0.33.\n",
    "```\n",
    "\n",
    "We have used Jaccard distance which is a measure of how dissimilar two sets are. It is the complement of the Jaccard index and can be found by subtracting the Jaccard Index from 100%.\n",
    "```\n",
    "For the above example, the Jaccard distance is 1 – 33.33% = 66.67%.\n",
    "```\n",
    "\n",
    "In set notation, subtract from 1 for the Jaccard Distance:\n",
    "```\n",
    "D(X,Y) = 1 – J(X,Y)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question ii)\n",
    "Why did you think that your distance function would do better than the first one?\n",
    "\n",
    "In the first distance function, we consider complete set of tokens from a text and then calculate distance. In this way, we also consider reduntant tokens which are not neccessary for comparison of text for sentimental analysis.  \n",
    "\n",
    "In my distance calculation methods, especially \"Refined Intersection Distance\", we have removed the redundant texts which gives us only relevant tokens for comparing and calculating distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question iii)\n",
    "What is the confusion matrix for k = 1?  \n",
    "(Calculations done under **\"Running for all Distances for Comparison\"** Section)  \n",
    "**Using Refined Intersection Distance:**    \n",
    "True Positive = 229     False Negative = 44  \n",
    "False Positive = 92\t    True Negative = 135  \n",
    "\n",
    "**Using Jaccard Distance:**  \n",
    "True Positive = 206     False Negative = 67  \n",
    "False Positive = 112\tTrue Negative = 115  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question iv)\n",
    "Report the accuracy, the true positive rate, and the false positive rate, on the test set for k = 1?  \n",
    "(Calculations done under **\"Running for all Distances for Comparison\"** Section)\n",
    "\n",
    "**Using Refined Intersection Distance:**\n",
    "Accuracy = 72.8  \n",
    "True Positive Rate = 0.8388278388278388  \n",
    "False Positive Rate = 0.4052863436123348  \n",
    "\n",
    "**Using Jaccard Distance:**\n",
    "Accuracy = 64.2  \n",
    "True Positive Rate = 0.7545787545787546   \n",
    "False Positive Rate =  0.4933920704845815"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question v)\n",
    "What is the confusion matrix for k = 5?\n",
    "\n",
    "(Calculations done under **\"Running for all Distances for Comparison\"** Section)  \n",
    "**Using Refined Intersection Distance:**    \n",
    "True Positive = 236     False Negative = 37  \n",
    "False Positive = 93     True Negative = 134  \n",
    "\n",
    "**Using Jaccard Distance:**  \n",
    "True Positive = 220     False Negative = 53  \n",
    "False Positive = 113\tTrue Negative = 114  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question vi)\n",
    "Report the accuracy, the true positive rate, and the false positive rate, on the test set for k = 5?  \n",
    "(Calculations done under **\"Running for all Distances for Comparison\"** Section)\n",
    "\n",
    "**Using Refined Intersection Distance:**\n",
    "Accuracy = 74.0  \n",
    "True Positive Rate = 0.8644688644688645  \n",
    "False Positive Rate = 0.40969162995594716 \n",
    "\n",
    "**Using Jaccard Distance:**\n",
    "Accuracy = 66.8   \n",
    "True Positive Rate = 0.8058608058608059   \n",
    "False Positive Rate =  0.4977973568281938"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question vii)\n",
    "Did your distance function achieve higher accuracy (for k = 1 and k = 5) than the first distance function?  \n",
    "For the Comparison shown in **\"Running for all Distances for Comparison\"** Section, both of our distance functions achieve higher accuracy than first distance function:  \n",
    "\n",
    "**Using Default Distance:**\n",
    "<ul>\n",
    "    <li>For K = 1, Accuracy = 60.4</li> \n",
    "    <li>For K = 5, Accuracy = 60.6</li>\n",
    "</ul>\n",
    "\n",
    "**Using Refined Intersection Distance:**\n",
    "<ul>\n",
    "    <li>For K = 1, Accuracy = 72.8</li> \n",
    "    <li>For K = 5, Accuracy = 74.0</li>\n",
    "</ul>\n",
    "\n",
    "**Using Jaccard Distance:**\n",
    "<ul>\n",
    "    <li>For K = 1, Accuracy = 64.2</li> \n",
    "    <li>For K = 5, Accuracy = 66.8</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
